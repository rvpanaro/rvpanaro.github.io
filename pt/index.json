[{"authors":["renato"],"categories":null,"content":"Panaro is an accredited statistician currently enrolled in the PhD program in Statistics at the University of São Paulo. Passionate about data-driven decision, extreme traveler, night programmer and game player. Has expertise in univariate statistical inference, structural equation models, survival regression models and development of R packages.\n","date":1564971194,"expirydate":-62135596800,"kind":"taxonomy","lang":"pt","lastmod":1564971194,"objectID":"f0e54a125f2b5b509beeecc3c396bcd5","permalink":"/pt/authors/renato/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/pt/authors/renato/","section":"authors","summary":"Panaro is an accredited statistician currently enrolled in the PhD program in Statistics at the University of São Paulo. Passionate about data-driven decision, extreme traveler, night programmer and game player. Has expertise in univariate statistical inference, structural equation models, survival regression models and development of R packages.","tags":null,"title":"Renato Panaro","type":"authors"},{"authors":["silvio"],"categories":null,"content":"Silvio Cabral has experience in the areas of probability and statistics, regression analysis, machine learning, neural networks and deep learning. Currently, his main projects involve problems with the classification and segmentation of images and music, using machine learning techniques.\n","date":1564971194,"expirydate":-62135596800,"kind":"taxonomy","lang":"pt","lastmod":1564971194,"objectID":"5b4fc9e0756190588f8b91cbab8579e3","permalink":"/pt/authors/silvio/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/pt/authors/silvio/","section":"authors","summary":"Silvio Cabral has experience in the areas of probability and statistics, regression analysis, machine learning, neural networks and deep learning. Currently, his main projects involve problems with the classification and segmentation of images and music, using machine learning techniques.","tags":null,"title":"Silvio Cabral","type":"authors"},{"authors":["rumenick"],"categories":null,"content":"Statistician, said classic of birth and Bayesian for convenience, has dedicated himself to simplifying the teaching of statistical science, R and related topics for diverse audiences. Expert on teaching statistical reasoning used in conclusions or data-based applications. Currently, he lives a trilemma, of how to divide the time to finish his articles, to teach biostatistics for future pharmacists and to manage consultancy activities. Remembering that we still have Rn00bs. :D\n","date":1557972794,"expirydate":-62135596800,"kind":"taxonomy","lang":"pt","lastmod":1557972794,"objectID":"cc7a6800425ed41ef7d634a38c57d02f","permalink":"/pt/authors/rumenick/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/pt/authors/rumenick/","section":"authors","summary":"Statistician, said classic of birth and Bayesian for convenience, has dedicated himself to simplifying the teaching of statistical science, R and related topics for diverse audiences. Expert on teaching statistical reasoning used in conclusions or data-based applications. Currently, he lives a trilemma, of how to divide the time to finish his articles, to teach biostatistics for future pharmacists and to manage consultancy activities. Remembering that we still have Rn00bs. :D","tags":null,"title":"Rume(Nick) Pereira da Silva","type":"authors"},{"authors":["Silvio Cabral","Renato Panaro"],"categories":["Curiosidades"],"content":"  body { text-align: justify}  Por que modelar? E se um endocrinologista especializado em diabetes pudesse dizer se é provável que o paciente tenha ou não diabetes, baseado apenas na idade e no consumo de açúcar dele? Já pensou como isso poderia reduzir os custos do paciente, do plano de saúde e até mesmo do Sistema Único de Saúde (SUS)?\nSomente em 2015 houveram cerca de 1,4 bilhões de consultas médicas. Se em \\(2\\%\\) dessas consultas médicas for solicitado algum tipo de exame laboratorial para diabetes seriam gastos cerca de pelo menos 28 milhões de reais apenas com exames, supondo que cada exame custe no mínimo 1 real. Porém, se tivermos um modelo de classificação como o do exemplo acima, o sistema economizaria com pacientes que provavelmente não são diabéticos e alocaria o valor referente ao custo dos exames para a construção de novas unidades de atendimento.\nOk, então vamos seguir com esse exemplo. Suponha foi medida a Quantidade diária de Açúcar Consumido (X1) e a idade (X2) de cada paciente atendido.\nFigura: Gráfico de dispersão da Quantidade de Açúcar (X1) pela Idade (X2).\n Observamos um certo padrão com relação aos pacientes que então foram diagnosticados diabéticos (vermelho) e os que foram classificados como não diabéticos (preto). Note a presença de uma região em que só há pacientes diabéticos e a de outra onde só estão presentes os pacientes saudáveis.\n O que é um Modelo de Decisão? Criar um modelo nada mais é do que propor uma fórmula matemática para delimitar essas duas regiões baseada em dados observados, ou seja, uma técnica que permita determinar uma curva/superfície, onde, abaixo dela estão os pacientes saudáveis e acima dela os pacientes estão os diabéticos, de acordo com X1 e X2.\nFigura: Exemplo de Modelo de Decisão.\n Agora que você já entendeu um pouco sobre o que é modelagem e porque modelar, vamos ao que interessa! Quais métodos você pode usar para criar modelos de decisão? Atualmente existem vários, como por exemplo:\n Perceptron Modelo Logístico Árvore de Decisão Support Vector Machine (SVM) Naive Bayes K-Nearest Neighbours Análise de Discriminante  Sendo assim, um modelo de decisão nada mais é do que uma forma de representar a realidade. Mais precisamente, um modelo refere-se a alguma forma de representação simbólica de nossas suposições sobre a realidade, Mayag (n.d.). Nesse exemplo, a linha preta, que separa os pacientes diabéticos dos saudáveis, é chamada de superfície/curva de decisão. Até a próxima!\n Referências Mayag, B. n.d. “Introduction to Decision Modeling.” University Paris Dauphine.\n   ","date":1564971194,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1564971194,"objectID":"bc51d49c242dd6f5bd16d14696dff6f8","permalink":"/pt/post/modelling/","publishdate":"2019-08-04T21:13:14-05:00","relpermalink":"/pt/post/modelling/","section":"post","summary":"Descubra porque os Cientistas de Dados adoram um Modelo de Decisão.","tags":["curiosidades","R","S","Modelagem","Decisão","pt"],"title":"O que é Decision Modelling?","type":"post"},{"authors":null,"categories":null,"content":"","date":1563840000,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1563840000,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"/pt/contact/","publishdate":"2019-07-23T00:00:00Z","relpermalink":"/pt/contact/","section":"","summary":"Need some help?","tags":null,"title":"Contact","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1563840000,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1563840000,"objectID":"ac11af225824ed72a47ab3e0144b7a71","permalink":"/pt/author/","publishdate":"2019-07-23T00:00:00Z","relpermalink":"/pt/author/","section":"","summary":"Meet our squad  !","tags":null,"title":"Writers","type":"widget_page"},{"authors":["Renato Panaro","Rume(Nick) Pereira da Silva"],"categories":["EstatComp"],"content":"  body { text-align: justify}  O que é? O Bootstrap foi uma das primeiras técnicas estatísticas intensivas de reamostragem para computar a variância de um conjunto de dados estatísticos, construir intervalos de confiança e realizar testes de hipóteses sobre parâmetros de interesse, esse método foi introduzido pelo estatístico estadunidense Bradley Efron em 1979. Efron seguiu o espírito de Tuckey para nomear a técnica (veja o post sobre jackknife).\nBootstrap methods: another look at the jackknife, Efron (1979).\n De onde vem o termo Bootstrap? Em inglês, bootstrap é sinônimo de alça da bota, logo, remete a algo que precisa ser alavancado por esforço próprio. A forma abreviada “boot” é muito popular quando usada para referir-se aos comandos iniciais necessários para carregar o sistema operacional do computador, Oxford (2014). Porém, segundo Scholz (2007), a motivação foi fazer uma analogia ao ato de puxar a si mesmo e seu cavalo para fora de um atoleiro, como na ficção As Aventuras do Barão Munchausen. O detalhe é que na ficção o Barão usa como recurso o seu próprio rabo de cavalo e não a alça da bota, no entanto, essa versão para a motivação de Efron ganhou força após tradução do artigo de Diaconis and Efron (1983) para alemão em que o uso da expressão “die M¨unchhausen Methode” é feito pelos autores.\nFigura: Capa do Livro Aventuras do Barão Munchausen.\n  Qual é a ideia do método? Em estatística, os métodos de bootstrap são uma classe de métodos que estimam a distribuição de uma população por reamostragem. A amostra observada é tratada como uma população e amostras aleatórias com reposição são geradas (reamostradas) a partir dela. Com o bootstrap ou bootstrapping é possível estudar características da população a partir dessa pseudo-população e extrair inferências.\nFigura: Representação do Bootstrap com 3 “reamostras” de tamanho 5.\n  A amostra Bootstrap é do mesmo tamanho (n = 5) da amostra original (pode ser maior ou menor).\n Cada amostra Boostrap nada mais é do que uma reamostra, ou seja, uma amostragem simples com reposição feita a partir da amostra original.\n O fato de ser com reposição significa que o valor é reposto ao conjunto de possíveis valores de retirada.\n B é o número arbitrário de réplicas (número de reamostras) bootstrap.\n   Como e por que funciona? Vimos que os métodos de reamostragem como Jackknife e Bootstrap se baseiam em reamostras de uma amostra proveniente da população alvo em estudo. No caso do Bootstrap, \\(\\mathbf{x}=(x_1, \\dots,x_n)\\) é uma amostra aleatória (a.a.) com reposição observada de uma distribuição populacional desconhecida \\(F_X\\).\nLogo, seja \\(X^∗\\) a variável aleatória que representa da seleção de uma observação aleatoriamente de \\(\\mathbf{x}\\), então \\[p=P(X^∗=x_i)=\\frac{1}{n},~i=1,\\dots,n\\].\nObserve que \\(X^*\\) segue distribuição uniforme discreta no conjunto \\(\\{x_1,\\dots,x_n\\}\\). Portanto, neste caso, reamostrar B vezes é equivale a gerar B amostras bootstrap de tamanho \\(m\\) com variáveis independentes e identicamente distribuídas (i.i.d.) \\[\\mathbf{X^*} = (X^*_1,X^*_2,\\dots,X^*_m), \\text{ com }X^* \\sim Unif\\{x_1,\\dots,x_n\\}.\\]\nExemplo 7.1 Rizzo (2007): Suponha Suponha \\(\\mathbf{x}={2,2,1,1,5,4,4,3,1,2}\\) uma a.a. observada de tamanho 10. Note que, dada amostra aleatória \\(\\mathbf{x}\\) , há 5 valores possíveis para formar uma reamostra \\(X^∗\\) de \\(\\mathbf{x}\\) com probabilidades:\n\\[P(X=k)= \\begin{cases} 0,3; \\text{ se } k=1\\\\ 0,3; \\text{ se } k=2\\\\ 0,1; \\text{ se } k=3\\\\ 0,2; \\text{ se } k=4\\\\ 0,1; \\text{ se } k=5\\\\ \\end{cases}\\]\nNote que cada elemento pertencente ao conjunto \\(\\{2,2,1,1,5,4,4,3,1,2\\}\\) tem probabilidade de retirada \\(p=1/10\\), logo, as probabilidades são somadas a medida que os valores se repetem nesse conjunto.\nVisualização no R:\nx \u0026lt;- c(2,2,1,1,5,4,4,3,1,2) n \u0026lt;- length(x) barplot(table(x)/n, bty = \u0026quot;n\u0026quot;, ylab = expression(P(X == k)), xlab = expression(k), col = \u0026quot;darkblue\u0026quot;) Perceba que a distribuição acumulada \\(F_X^∗\\) da amostra bootstrap com a distribuição empírica que pode ser usada como uma aproximação de \\(F_X\\).\nLembre que \\(F_n\\) é uma distribuição discreta com pesos iguais para cada ponto amostral, \\(F_n\\) é definida como uma proporção amostral \\(F_n(t)=\\sum\\limits_{i=1}^n \\#\\{x_i \\le t\\}I_{(x_i \\le t)}\\).\n\\[ F_n(k)=F_X^∗(k)=\\begin{cases} 0; \\text{ se } k\u0026lt;1 \\\\ 0,3; \\text{ se } 1 \\le k \u0026lt; 2 \\\\ 0,6; \\text{ se } 2 \\le k\u0026lt;3 \\\\ 0,7; \\text{ se } 3 \\le k\u0026lt;4 \\\\ 0,9; \\text{ se } 4 \\le k\u0026lt;5 \\\\ 1; \\le k≥5. \\\\ \\end{cases}\\]\nCom auxílio do R é possível visualizar que as duas distribuições de fato coincidem coincidem, logo, reamostrar de \\(x\\) equivale a gerar valores da distribuição \\(F_n(x)\\).\npar(mfrow = c(1,2)) barplot(c(c(\u0026#39;0\u0026#39;=0), cumsum(table(x)/n)), bty = \u0026quot;n\u0026quot;, main = \u0026quot;Dist. Acumulada\u0026quot;, ylab = paste0(expression(F[X]),\u0026#39;*\u0026#39; ,expression((k))), xlab = expression(x[i]), col = \u0026quot;darkblue\u0026quot;) plot(ecdf(x), main = \u0026quot;Dist. Empírica\u0026quot;, bty= \u0026quot;n\u0026quot;, ylab = expression(F[n](k))) Segundo Rizzo (2007), há duas grandes suposições no método bootstrap.\n A função de distribuição empírica \\(F_n\\) é uma boa aproximação para \\(F_X\\), então a distribuição do estimador bootstrap \\(\\hat \\theta^*\\) é similar à distribuição desconhecida do estimador proposto originalmente \\(\\hat \\theta\\).\n A distribuição empírica das réplicas bootstrap é uma boa aproximação para \\(F_n\\).\n  Portanto, a tarefa de fazer inferências sobre \\(\\theta\\) se reduz a aprender sobre a distribuição bootstrap de \\(\\hat\\theta^*\\). Logo, para cada amostra bootstrap indexada por \\(b=1,\\dots,B\\), calcula-se \\(\\hat\\theta^{*(b)}\\) e a estimativa bootstrap da distribuição do estimador \\(F_{\\hat\\theta}(.)\\) é a distribuição empírica das réplicas \\(\\hat\\theta^{*(1)},\\dots,\\hat\\theta^{*(B)}\\).\nA amostra acima é na verdade uma amostra de uma \\(Poisson(2)\\). Um grande número de réplicas produz uma boa estimativa de \\(F_n\\), mas não uma boa estimativa de \\(F_X\\). A violação da segunda suposição ocorre porque independente do número de réplicas, as amostras de bootstrap nunca incluirão o valor zero, Rizzo (2007).\n Conclusão A distribuição da população finita representada pela amostra pode ser considerada uma pseudo-população com características semelhantes às da verdadeira população. Mais do que isso, aprendemos que através da geração repetida de amostras aleatórias desta pseudo-população (reamostragem), a distribuição amostral de uma estatística pode ser estimada. Logo, as estimativas de bootstrap de uma distribuição de amostragem são análogas à ideia de estimativa de densidade. Saiba que há diversas aplicações avançadas do Bootstrap, as propriedades de um estimador como viés ou erro padrão, por exemplo, podem ser estimadas por métodos de reamostragem.\n “The bootstrap is rarely the star of statistics, but it is the best supporting actor”, Bradley Efron.\n  Referências Efron, B. 1979. “Bootstrap Methods: Another Look at the Jackknife.” The Annals of Statistics, 1–26.\n Rizzo, Maria L. 2007. Statistical Computing with R. Chapman; Hall/CRC.\n   ","date":1557972794,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1557972794,"objectID":"049a03b8e36766ed67ac6114d85b7cae","permalink":"/pt/post/bootstrap/","publishdate":"2019-05-15T21:13:14-05:00","relpermalink":"/pt/post/bootstrap/","section":"post","summary":"Aprenda Bootstrap em 5 minutos!","tags":["bootstrap","R","estatística","não-paramétrica","computacional","reamostragem","pt"],"title":"Intro ao Bootstrap","type":"post"},{"authors":["Renato Panaro","Rume(Nick) Pereira da Silva"],"categories":["EstatComp"],"content":"  body { text-align: justify}  O que é? Em estatística, o nome jacknife foi usado por Tukey (1958) para descrever uma perspectiva geral para realizar testes de hipóteses e calcular intervalos de confiança. O Jackknife consiste em recalcular um particular estimador, eliminando sistematicamente cada observação individual (leave-one-out)!\n Como funciona? Por exemplo, uma amostra de tamanho \\(n=4\\) pode ser representada da seguinte forma:\nFigura: Representação do Jackknife em cores.\n  Jack 1 deixa apenas a observação amarela de fora,\n Jack 2 retoma a observação excluída anteriormente (amarela) e deixa de fora a observação verde, assim por diante.\n As cores das caselas representam observações que na prática são mensurações de um particular evento (números), que inclusive podem coincidir.\n Deixa-se de fora um por vez até que se obtenha n amotras, cada uma composta pelas observações da amostra original exceto a j-ésima observação.\n   Um pouco de Estatística Conceitos fundamentais de Estatística são necessários para compreender o funcionamento de métodos de estimação por reamostragem, afinal todo estimador é necessariamente uma estatítica do qual extrairemos inferências sobre uma quantidade de interesse (o parâmetro)!\nEm poucas palavras, qualquer função da amostra que não depende do parâmetro é uma estatística, por exemplo:\n\\[\\hat\\theta(X_1, X_2, \\dots, X_n) = \\frac{1}{n}\\sum\\limits_{i=1}^{n}X_i = \\bar{X}.\\]\npode ser o estimador da média populacional \\(\\theta = \\mu\\), quando um estimador é aplicado a uma amostra proveniente da população em estudo obtemos um valor real \\(t\\), chamado estimativa.\nPor exemplo, considere uma amostra uma amostra \\(\\mathbf{x}\\) de tamanho \\(n = 4\\) \\(\\mathbf{x}=(x_1,x_2,x_3, x_4)=(4,1,2,3)\\) e o estimador \\(\\bar{X}\\) para o parâmetro \\(\\theta\\), ou seja, \\(\\hat\\theta = \\bar{X}\\). A estimativa pontual é obtida quando aplicamos a estatística referente ao estimador aos dados provenientes de uma amostra da população de interesse, nesse caso, a estimativa pontual é dada por \\(t = \\frac{1}{4}\\sum\\limits_{i=1}^{4}x_i = \\frac{4+1+2+3}{4}=2,5.\\)\n Como fazer Inferência baseada no método Jackknife? No contexto de Inferência Estatística, além das estimavas pontuais, ainda é possível obter estimativas intervalares e realizar testes de hipóteses com base em amostras observadas da população alvo (Veja Morettin (2017)). Nesta breve introdução será apresentada a estimativa pontual Jackknife e sua estimativa intervalar correspondente, em que não há qualquer suposição sobre a distribuição dos dados em estudo.\n1- Estimativa Parcial Dada uma amostra \\((x_1,x_2,\\dots ,x_n)\\) qualquer e um estimador para o parâmetro de interesse, a estimativa parcial consiste em simplesmente obter estimativas pontuais \\(t_{-j}\\) para cada amostra Jack!\n 2- Pseudo-valores Os pseudo-valores \\(t^∗_j\\) farão parte do cáculo da estimativa pontual Jack abaixo. \\[t^∗_j = nt-(n-1)t_{-j}\\] Note que \\(t\\) é a estimativa calculada usando a amostra original (sem retirada) e que \\(n\\) é o tamanho da amostra.\n 3 - Estimativa Pontual Jackknife A estimativa pontual Jack é a média aritmética dos pseudo-valores.\n\\[t^*=\\frac{1}{n}\\sum\\limits_{j=1}^{n}t^∗_j \\] Logo, o cálculo da estimativa Jack consiste apenas em computar média aritmética dos pseudo-valores obtidos com as amostras Jackknife.\n  Só isso? Veja o exemplo Exemplo 2.1, Manly (2006): Suponha que seja extraída uma amostra aleatória de tamanho 20 de uma certa população na qual o desvio-padrão populacional \\(\\sigma\\) é o parâmeto de interesse do estudo. Obtenha uma estimativa intervalar para \\(\\sigma\\) a partir de \\(\\hat\\sigma=\\frac{1}{n}\\sum\\limits_{i=1}^n (X_i−\\bar{X})^2\\).\n\\[ 3,56;0,69;0,10;1,84;3,93;1,25;0,18;1,13;0,27;0,50;0,67;0,01;0,61;0,82;1,70;0,39;0,11;1,20;1,21;0,72. \\]\nObs.:\n Não é recomendável fazer suposições sobre a distribuição da amostra ou do estimador para uma amostra de tamanho 20.\n Além disso, não se sabe qual é a distribuição da população da qual provém a amostra.\n No entanto, o método jackknife permite obter estimativas pontuais e intervalares para o parâmetro.\n  Vamos aplicar essa técnica de reamostragem no R!\namostra \u0026lt;- c(3.56, 0.69, 0.10, 1.84, 3.93, 1.25, 0.18, 1.13, 0.27, 0.50, 0.67, 0.01, 0.61, 0.82, 1.70, 0.39, 0.11, 1.20, 1.21, 0.72)  O tamanho da amostra é \\(n=20\\), logo teremos 20 amostras jack de tamanho \\((n−1)=19\\).\nn \u0026lt;- length(amostra) # tamanho da amostra n ## [1] 20 As amostras Jackknife podem ser visualizadas de forma matricial, onde cada linha da matrizjack corresponde à amostra exceto o i-ésimo valor. No Rscript, o comando for() foi utilizado para tal.\nmatrizjack \u0026lt;- matrix(amostra, n, n, byrow = T) for ( i in 1:n){ matrizjack[i,i] \u0026lt;- NA } pander::pander(matrizjack, split.table = Inf)     NA 0.69 0.1 1.84 3.93 1.25 0.18 1.13 0.27 0.5 0.67 0.01 0.61 0.82 1.7 0.39 0.11 1.2 1.21 0.72  3.56 NA 0.1 1.84 3.93 1.25 0.18 1.13 0.27 0.5 0.67 0.01 0.61 0.82 1.7 0.39 0.11 1.2 1.21 0.72  3.56 0.69 NA 1.84 3.93 1.25 0.18 1.13 0.27 0.5 0.67 0.01 0.61 0.82 1.7 0.39 0.11 1.2 1.21 0.72  3.56 0.69 0.1 NA 3.93 1.25 0.18 1.13 0.27 0.5 0.67 0.01 0.61 0.82 1.7 0.39 0.11 1.2 1.21 0.72  3.56 0.69 0.1 1.84 NA 1.25 0.18 1.13 0.27 0.5 0.67 0.01 0.61 0.82 1.7 0.39 0.11 1.2 1.21 0.72  3.56 0.69 0.1 1.84 3.93 NA 0.18 1.13 0.27 0.5 0.67 0.01 0.61 0.82 1.7 0.39 0.11 1.2 1.21 0.72  3.56 0.69 0.1 1.84 3.93 1.25 NA 1.13 0.27 0.5 0.67 0.01 0.61 0.82 1.7 0.39 0.11 1.2 1.21 0.72  3.56 0.69 0.1 1.84 3.93 1.25 0.18 NA 0.27 0.5 0.67 0.01 0.61 0.82 1.7 0.39 0.11 1.2 1.21 0.72  3.56 0.69 0.1 1.84 3.93 1.25 0.18 1.13 NA 0.5 0.67 0.01 0.61 0.82 1.7 0.39 0.11 1.2 1.21 0.72  3.56 0.69 0.1 1.84 3.93 1.25 0.18 1.13 0.27 NA 0.67 0.01 0.61 0.82 1.7 0.39 0.11 1.2 1.21 0.72  3.56 0.69 0.1 1.84 3.93 1.25 0.18 1.13 0.27 0.5 NA 0.01 0.61 0.82 1.7 0.39 0.11 1.2 1.21 0.72  3.56 0.69 0.1 1.84 3.93 1.25 0.18 1.13 0.27 0.5 0.67 NA 0.61 0.82 1.7 0.39 0.11 1.2 1.21 0.72  3.56 0.69 0.1 1.84 3.93 1.25 0.18 1.13 0.27 0.5 0.67 0.01 NA 0.82 1.7 0.39 0.11 1.2 1.21 0.72  3.56 0.69 0.1 1.84 3.93 1.25 0.18 1.13 0.27 0.5 0.67 0.01 0.61 NA 1.7 0.39 0.11 1.2 1.21 0.72  3.56 0.69 0.1 1.84 3.93 1.25 0.18 1.13 0.27 0.5 0.67 0.01 0.61 0.82 NA 0.39 0.11 1.2 1.21 0.72  3.56 0.69 0.1 1.84 3.93 1.25 0.18 1.13 0.27 0.5 0.67 0.01 0.61 0.82 1.7 NA 0.11 1.2 1.21 0.72  3.56 0.69 0.1 1.84 3.93 1.25 0.18 1.13 0.27 0.5 0.67 0.01 0.61 0.82 1.7 0.39 NA 1.2 1.21 0.72  3.56 0.69 0.1 1.84 3.93 1.25 0.18 1.13 0.27 0.5 0.67 0.01 0.61 0.82 1.7 0.39 0.11 NA 1.21 0.72  3.56 0.69 0.1 1.84 3.93 1.25 0.18 1.13 0.27 0.5 0.67 0.01 0.61 0.82 1.7 0.39 0.11 1.2 NA 0.72  3.56 0.69 0.1 1.84 3.93 1.25 0.18 1.13 0.27 0.5 0.67 0.01 0.61 0.82 1.7 0.39 0.11 1.2 1.21 NA    Define-se uma função chamada sigma_chapeu() que irá representar o estimador \\(\\hat\\sigma\\) dado na questão.\nsigma_chapeu \u0026lt;- function(x){ x \u0026lt;- x[!is.na(x)] # remove dados faltantes xbarra \u0026lt;- mean(x) desvio \u0026lt;- x-mean(x) n \u0026lt;- length(x) return(sqrt(sum(desvio^2)/n)) } t_amostra \u0026lt;- sigma_chapeu(amostra); t_amostra ## [1] 1.032848 Para o cálculo das estimativas parciais \\((t_{−1},t_{−2},\\dots,t_{−n})\\), a função apply() é usada abaixo para aplicar sigma_chapeu() em todas as linhas “MARGIN=1” da matrizjack, o uso de funções apply evita loops como for() e while(), o excesso de loops pode tornar a programação computacionalmente ineficiente.\nt_par \u0026lt;- apply(X = matrizjack, MARGIN = 1 , FUN = sigma_chapeu) print(t_par) ## [1] 0.8788364 1.0563893 1.0360975 1.0430060 0.8134128 1.0585751 1.0399595 ## [8] 1.0594885 1.0438813 1.0519008 1.0560070 1.0313246 1.0547329 1.0583612 ## [15] 1.0483872 1.0484218 1.0365998 1.0590473 1.0589633 1.0569234 Agora, os pseudo-valores são facilmente calculados de acordo com a fórmula definida.\npseudov \u0026lt;- n * t_amostra-(n-1) * t_par print(pseudov) ## [1] 3.9590656 0.5855601 0.9711049 0.8398438 5.2021138 0.5440315 0.8977269 ## [8] 0.5266770 0.8232137 0.6708425 0.5928255 1.0617899 0.6170325 0.5480939 ## [15] 0.7376002 0.7369426 0.9615623 0.5350591 0.5366545 0.5754139 Por fim, a estimava pontual jackknife é dada pela média aritmética dos pseudo-valores.\nestjack \u0026lt;- mean(pseudov) print(estjack) ## [1] 1.096158 Segundo Manly (2006), a estimativa intervalar aproximada para \\(\\sigma\\) a um nível de \\(100(1−\\alpha)\\%\\) de confiança é dada por um intervalo de confiança t-Student:\n\\[\\left[t^*\\pm t_{\\frac{\\alpha}{2},n-1}\\times\\frac{s}{\\sqrt{n}}\\right]\\]\nAo fixar \\(\\alpha = 0,05\\), temos o intervalo Jackknife de 95% de confiança:\n alfa \u0026lt;- 1-0.95 s \u0026lt;- sd(pseudov) L \u0026lt;- estjack - qt(1-alfa/2,df = n-1) * s/sqrt(n) U \u0026lt;- estjack + qt(1-alfa/2,df = n-1) * s/sqrt(n) c(\u0026quot;L\u0026quot;=L,\u0026quot;U\u0026quot;=U) ## L U ## 0.525173 1.667142  Conclusão O termo jackknife (canivete em tradução livre) remete à portabilidade e a possibilidade de uso em diversas situações. Essa técnica, desenvolvida por Maurice Quenouille (1949), é particularmente útil em situações em que a distribuição do estimador é desconhecida. O método Jackknife não é computacionalmente intensivo e é facilmente implementado com conhecimento básico em inferência e um pouco de R! Considerando que a amostra provém de uma população Exponencial(1), obtivemos um intervalo de confiança que contém o real valor do parâmetro \\(\\sigma = 1\\) com uma amostra de tamanho 20, usando um estimador do qual não sabemos a distribuição.\n Referências Manly, Bryan FJ. 2006. Randomization, Bootstrap and Monte Carlo Methods in Biology. Chapman; Hall/CRC.\n Morettin, Wilton Oliveira, Pedro Alberto e Bussab. 2017. Estatı́stica Básica. Editora Saraiva.\n   ","date":1557886394,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1557886394,"objectID":"ac23367bd614776e985257a2c7f18a30","permalink":"/pt/post/jackknife/","publishdate":"2019-05-14T21:13:14-05:00","relpermalink":"/pt/post/jackknife/","section":"post","summary":"Saiba o poder do canivete em momentos de dificuldade.","tags":["jackknife","R","estatística","intro","computacional","reamostragem","pt"],"title":"Conheça o Jackknife","type":"post"},{"authors":null,"categories":null,"content":"O conteúdo disponibilizado neste website é de livre acesso, de autoria e coautoria de escritores independentes, produzido com o intuito de colaborar com a comunidade científica. Sendo assim, o material é original e, portanto, não é permitida a reprodução ou veiculação do mesmo, uma vez que o uso da obra intelectual deve ser recompensado segundo a Lei nº 9.610 de 1998. No entanto, escritores externos, novos colabores e outros parceiros são muito bem-vindos. Em caso de dúvidas e sugestões contate o Rn00bs por e-mail, contato@rn00bs.com.br. ","date":1557442800,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1557442800,"objectID":"18d05a63a1c8d7ed973cc51838494e41","permalink":"/pt/privacy/","publishdate":"2019-05-10T00:00:00+01:00","relpermalink":"/pt/privacy/","section":"","summary":"O conteúdo disponibilizado neste website é de livre acesso, de autoria e coautoria de escritores independentes, produzido com o intuito de colaborar com a comunidade científica. Sendo assim, o material é original e, portanto, não é permitida a reprodução ou veiculação do mesmo, uma vez que o uso da obra intelectual deve ser recompensado segundo a Lei nº 9.610 de 1998. No entanto, escritores externos, novos colabores e outros parceiros são muito bem-vindos.","tags":null,"title":"","type":"page"},{"authors":["Silvio Cabral","Renato Panaro"],"categories":["Curiosidades"],"content":"  body { text-align: justify}  A liguagem R de programação é considerada uma linguagem de voltada para os usuários de Estatística e Ciência de Dados. E antes do R? Como se fazia uma análise exploratória? E um teste t?\nVocê consegue imaginar o seguinte cenário? A décadas atrás um professor de Estatística utilizava vários softwares para possibilitar suas análises e progredir com sua pesquisa. No entanto, durante suas aulas a missão de ensinar a cada um de seus alunos como usar todos eles se tornava árdua, uma vez que outros softwares surgiriam nos próximos anos. Os softwares já disponíveis no mercado, por sua vez, eram de alto custo e, portanto, a maioria dos alunos dificilmente teria acesso à esse ferramental após a conclusão de curso.\n Ainda há mais problemas! A questão é: Como lidar com tais softwares dada as dificuldades financeiras dos estudantes ao deixarem a universidade? De quais softwares comprar as permissões e licenças? Bom, essa foi a motivação para Ihaka and Gentleman (1996), dois professores da Universidade de Auckland (Nova Zelândia) que se depararam com esse cenário incômodo. Coincidência ou não, em 1993 Ross teve acesso a um livro chamado “New S language”, que lhe trouxe uma ideia inusitada.\n “New S”?! Tomando como base as ideias da linguagem S, os dois professores produziram sua própria linguagem de computador para dar aulas sobre Estatística, e deram à ela o nome de R (que faz menção ao nome de seus criadores e também faz referencia à linguagem S que originou o R).\nDe acordo com Fox (2009), no início, o R era apenas distribuído entre os alunos que, após as aulas levavam cópias do recém criado software para casa. Contudo, essas cópias foram sendo repassadas entre os alunos e dos alunos para a comunidade, aumentando o interesse de diversos usuários sobre a linguagem. Até que, em julho de 1995, Ross e Robert começaram a disseminar o software R publicamente, já que uma nova linguagem de programação surgira, disponibilizando-a no servidor da universidade. O sucesso do R foi tanto, que após 2 anos a linguagem já tinha visibilidade mundial e despertou o interesse de muitos desenvolvedores, inclusive John Chambers, um dos idealizadores e criadores da linguagem S.\n E nos dias de hoje? Nos últimos anos o R se tornou o queridinho de muitas empresas, especialmente das gigantes do ramo da tecnologia, como Facebook e Google, atraídas pelas vantagens do R sobre outros softwares, como custo, rápidez e código aberto, além das excelentes funcionalidades para análises estatísticas. Curiosamente hoje, a linguagem está no top 3 das linguagens mais utilizadas por cientistas de dados e, certamente, é uma das mais utilizadas entre os estudantes da Estatística, Engenharia, Economia, Epidemiologia, Medicina e àreas afins.\n Referências Fox, John. 2009. “Aspects of the Social Organization and Trajectory of the R Project.” The R Journal 1 (2): 5–13.\n Ihaka, Ross, and Robert Gentleman. 1996. “R: A Language for Data Analysis and Graphics.” Journal of Computational and Graphical Statistics 5 (3): 299–314.\n   ","date":1556331194,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1556331194,"objectID":"f9ebdf0f8ba6ae33419c0718541d669d","permalink":"/pt/post/history/","publishdate":"2019-04-26T21:13:14-05:00","relpermalink":"/pt/post/history/","section":"post","summary":"Como será que tudo começou?","tags":["curiosidades","R","S","pt"],"title":"História do R","type":"post"},{"authors":["Rume(Nick) Pereira da Silva"],"categories":null,"content":"","date":1553608800,"expirydate":-62135596800,"kind":"page","lang":"pt","lastmod":1553608800,"objectID":"91b10bfdb43d680f0d73b7ef55fd3637","permalink":"/pt/talk/each/","publishdate":"2019-03-26T14:00:00Z","relpermalink":"/pt/talk/each/","section":"talk","summary":"Curso de Planejamento de Experimentos.","tags":["Planejamento de Experimentos","Epidemiologia","USP"],"title":"Planejamento e análise Estatística usando o R","type":"talk"}]