<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>rn00bs</title>
    <link>/authors/renato/</link>
    <description>Recent content on rn00bs</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2020</copyright>
    <lastBuildDate>Sun, 04 Aug 2019 21:13:14 -0500</lastBuildDate>
    
	    <atom:link href="/authors/renato/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>O que é Decision Modelling?</title>
      <link>/post/modelling/</link>
      <pubDate>Sun, 04 Aug 2019 21:13:14 -0500</pubDate>
      
      <guid>/post/modelling/</guid>
      <description>


&lt;style&gt;
body {
text-align: justify}
&lt;/style&gt;
&lt;div id=&#34;por-que-modelar&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Por que modelar?&lt;/h1&gt;
&lt;p&gt;E se um endocrinologista especializado em diabetes pudesse dizer se é provável que o paciente tenha ou não diabetes, baseado apenas na idade e no consumo de açúcar dele? Já pensou como isso poderia reduzir os custos do paciente, do plano de saúde e até mesmo do Sistema Único de Saúde (SUS)?&lt;/p&gt;
&lt;p&gt;Somente em 2015 houveram cerca de 1,4 bilhões de consultas médicas. Se em &lt;span class=&#34;math inline&#34;&gt;\(2\%\)&lt;/span&gt; dessas consultas médicas for solicitado algum tipo de exame laboratorial para diabetes seriam gastos cerca de pelo menos 28 milhões de reais apenas com exames, supondo que cada exame custe no mínimo 1 real. Porém, se tivermos um modelo de classificação como o do exemplo acima, o sistema economizaria com pacientes que provavelmente não são diabéticos e alocaria o valor referente ao custo dos exames para a construção de novas unidades de atendimento.&lt;/p&gt;
&lt;p&gt;Ok, então vamos seguir com esse exemplo. Suponha foi medida a Quantidade diária de Açúcar Consumido (X1) e a idade (X2) de cada paciente atendido.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;gallery/dispersao.jpg&#34; alt=&#34;Figura: Gráfico de dispersão da Quantidade de Açúcar (X1) pela Idade (X2).&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Figura: Gráfico de dispersão da Quantidade de Açúcar (X1) pela Idade (X2).&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Observamos um certo padrão com relação aos pacientes que então foram diagnosticados diabéticos (vermelho) e os que foram classificados como não diabéticos (preto). Note a presença de uma região em que só há pacientes diabéticos e a de outra onde só estão presentes os pacientes saudáveis.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;o-que-é-um-modelo-de-decisão&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;O que é um Modelo de Decisão?&lt;/h1&gt;
&lt;p&gt;Criar um modelo nada mais é do que propor uma fórmula matemática para delimitar essas duas regiões baseada em dados observados, ou seja, uma técnica que permita determinar uma curva/superfície, onde, abaixo dela estão os pacientes saudáveis e acima dela os pacientes estão os diabéticos, de acordo com X1 e X2.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;gallery/decisao.jpg&#34; alt=&#34;Figura: Exemplo de Modelo de Decisão.&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Figura: Exemplo de Modelo de Decisão.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Agora que você já entendeu um pouco sobre o que é modelagem e porque modelar, vamos ao que interessa! Quais métodos você pode usar para criar modelos de decisão? Atualmente existem vários, como por exemplo:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Perceptron&lt;/li&gt;
&lt;li&gt;Modelo Logístico&lt;/li&gt;
&lt;li&gt;Árvore de Decisão&lt;/li&gt;
&lt;li&gt;Support Vector Machine (SVM)&lt;/li&gt;
&lt;li&gt;Naive Bayes&lt;/li&gt;
&lt;li&gt;K-Nearest Neighbours&lt;/li&gt;
&lt;li&gt;Análise de Discriminante&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Sendo assim, um modelo de decisão nada mais é do que uma forma de representar a realidade. Mais precisamente, um modelo refere-se a alguma forma de representação simbólica de nossas suposições sobre a realidade, &lt;span class=&#34;citation&#34;&gt;Mayag (n.d.)&lt;/span&gt;. Nesse exemplo, a linha preta, que separa os pacientes diabéticos dos saudáveis, é chamada de superfície/curva de decisão. Até a próxima!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;referências&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;Referências&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-Mayag&#34;&gt;
&lt;p&gt;Mayag, B. n.d. “Introduction to Decision Modeling.” &lt;em&gt;University Paris Dauphine&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Bootstrap intro</title>
      <link>/post/bootstrap/</link>
      <pubDate>Wed, 15 May 2019 21:13:14 -0500</pubDate>
      
      <guid>/post/bootstrap/</guid>
      <description>


&lt;style&gt;
body {
text-align: justify}
&lt;/style&gt;
&lt;div id=&#34;what-is&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;What is?&lt;/h1&gt;
&lt;p&gt;Bootstrap was one of the first intensive statistical resampling techniques to compute the variance estimates, build confidence intervals and perform hypothesis tests on parameters of interest, this method was introduced by the American statistician Bradley Efron in 1979. Efron followed Tuckey’s spirit and named the technique after jackniffe (see the &lt;a href=&#34;/post/jackknife&#34;&gt;post&lt;/a&gt; about jackknife).&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Bootstrap methods: another look at the jackknife&lt;/em&gt;, &lt;span class=&#34;citation&#34;&gt;Efron (1979)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;where-does-the-term-bootstrap-come-from&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Where does the term Bootstrap come from?&lt;/h1&gt;
&lt;p&gt;Bootstrap refers to something that needs to be leveraged by its own effort. The abbreviated form “boot” is very popular when used to refer to the initial commands needed to load the computer’s operating system &lt;span class=&#34;citation&#34;&gt;(Oxford 2014)&lt;/span&gt;. However, the motivation was to make an analogy to the act of pulling yourself and your horse out of a quagmire &lt;span class=&#34;citation&#34;&gt;(Scholz 2007)&lt;/span&gt;, as in the fiction &lt;strong&gt;The Adventures of Baron Munchausen&lt;/strong&gt;. The detail is that in this fiction the Baron uses his own ponytail as a resource and not the boot strap, however, this version for Efron’s motivation gained strength after translation of the article by &lt;span class=&#34;citation&#34;&gt;(Diaconis and Efron 1983)&lt;/span&gt; into German in which the use of the expression “die M¨unchhausen Methode” is made by the authors.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;gallery/baron.jpg&#34; alt=&#34;Figure: Book cover Adventures of Baron Munchausen.&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Figure: Book cover &lt;strong&gt;Adventures of Baron Munchausen&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;what-is-the-idea-behind-the-method&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;What is the idea behind the method?&lt;/h1&gt;
&lt;p&gt;In statistics, bootstrap methods are a class of methods that estimate the distribution of a population by resampling. The observed sample is treated as a population and random samples with replacement are generated (resampled) from it. With bootstrap or bootstrapping it is possible to study the population as from it’s pseudo-population.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;gallery/bootstrapping.png&#34; alt=&#34;Figure: Representation of Bootstrap with 3 “resamples” of size 5.&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Figure: Representation of Bootstrap with 3 “resamples” of size 5.&lt;/p&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The Bootstrap sample is the same size (n = 5) as the original sample (it can also be larger or smaller).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Each Boostrap sample is nothing more than a resample, that is, a simple sampling with replacement made from the original sample.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The fact of being with replacement means that the just sorted value remain in the set of possible values to the next withdrawal.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;B is the arbitrary number of replicas (number of resamples) bootstrap.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;how-and-why-does-it-work&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How and why does it work?&lt;/h1&gt;
&lt;p&gt;We saw that resampling methods like jackknife and bootstrap are based on resamples from a sample from the target population under study. In the case of Bootstrap, &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x} = (x_1, \dots, x_n)\)&lt;/span&gt; is a random sample (r.s.) with observed replacement of an unknown population distribution &lt;span class=&#34;math inline&#34;&gt;\(F_X\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Therefore, let &lt;span class=&#34;math inline&#34;&gt;\(X^∗\)&lt;/span&gt; be the random variable that represents the selection of an observation randomly from &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x}\)&lt;/span&gt;, then
&lt;span class=&#34;math display&#34;&gt;\[p = P (X^∗=x_i) = \frac{1}{n}, ~i = 1, \dots, n.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Note that &lt;span class=&#34;math inline&#34;&gt;\(X^*\)&lt;/span&gt; follows a discrete uniform distribution in the set &lt;span class=&#34;math inline&#34;&gt;\(\{x_1, \dots, x_n \}\)&lt;/span&gt;. So, in this case, resampling B times is equivalent to generating B bootstrap samples of size &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; with independent and identically distributed variables (i.i.d.) &lt;span class=&#34;math display&#34;&gt;\[\mathbf{X^*} = (X^*_ 1, X^*_2, \dots, X^*_m), \text{ with } X^* \sim Unif \{x_1, \dots, x_n \}.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 7.1 &lt;span class=&#34;citation&#34;&gt;Rizzo (2007)&lt;/span&gt;&lt;/strong&gt;: Suppose
Suppose &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x} = {2,2,1,1,5,4,4,3,1,2}\)&lt;/span&gt; r.s. observed size 10. Note that, given random sample &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x}\)&lt;/span&gt;, there are 5 possible values to form a sample
&lt;span class=&#34;math inline&#34;&gt;\(X^∗\)&lt;/span&gt; of &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x}\)&lt;/span&gt; with probabilities:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
P (X = k) =
\begin {cases}
0.3; \text{if } k = 1 \\
0.3; \text{if } k = 2 \\
0.1; \text{if } k = 3 \\
0.2; \text{if } k = 4 \\
0.1; \text{if } k = 5 \\
\end {cases} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Also, note that each element belonging to the set &lt;span class=&#34;math inline&#34;&gt;\(\{2,2,1,1,5,4,4,3,1,2 \}\)&lt;/span&gt; has a probability of withdrawal &lt;span class=&#34;math inline&#34;&gt;\(p = 1/10\)&lt;/span&gt;, so the probabilities are added as the values are repeated in that set.&lt;/p&gt;
&lt;p&gt;Visualization in R:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- c(2,2,1,1,5,4,4,3,1,2)
n &amp;lt;- length(x)
barplot(table(x)/n, bty = &amp;quot;n&amp;quot;, ylab = expression(P(X == k)),
        xlab = expression(k), col = &amp;quot;darkblue&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/en/post/bootstrap/index_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Note that the accumulated &lt;span class=&#34;math inline&#34;&gt;\(F_X^∗\)&lt;/span&gt; distribution of the bootstrap sample with the empirical distribution that can be used as an approximation of &lt;span class=&#34;math inline&#34;&gt;\(F_X\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Remember that &lt;span class=&#34;math inline&#34;&gt;\(F_n\)&lt;/span&gt; is a discrete distribution with equal weights for each sample point, &lt;span class=&#34;math inline&#34;&gt;\(F_n\)&lt;/span&gt; is defined as a sample proportion &lt;span class=&#34;math inline&#34;&gt;\(F_n(t) = \sum \limits_{i = 1}^n \# \{x_i \le t \} I_{(x_i\le t)}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
F_n(k) = F_X^∗(k) = \begin{cases}
0; \text{se} k &amp;lt;1 \\
0.3; \text{se} 1 \le k &amp;lt;2 \\
0.6; \text{se} 2 \le k &amp;lt;3 \\
0.7; \text{se} 3 \le k &amp;lt;4 \\
0.9; \text{se} 4 \le k &amp;lt;5 \\
1; \le k \ge 5. \\
\end{cases}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;With the help of R, it is possible to visualize that the two distributions actually coincide, therefore, resampling of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is equivalent to generating values of the &lt;span class=&#34;math inline&#34;&gt;\(F_n (x)\)&lt;/span&gt; distribution.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;par(mfrow = c (1,2))
barplot (c (c (&amp;#39;0&amp;#39; = 0), cumsum (table (x) / n)), bty = &amp;quot;n&amp;quot;,
        main = &amp;quot;Accumulated Dist.&amp;quot;, ylab = paste0 (expression (F [X]), &amp;#39;*&amp;#39;, expression((k))),
        xlab = expression (x [i]), col = &amp;quot;darkblue&amp;quot;)

plot(ecdf (x), main = &amp;quot;Empirical Dist&amp;quot;, bty = &amp;quot;n&amp;quot;, ylab = expression(F [n] (k)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/en/post/bootstrap/index_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;
Therefore, one of the two following assumptions is made. Either the empirical distribution of bootstrap replicas is a good approximation for &lt;span class=&#34;math inline&#34;&gt;\(F_n\)&lt;/span&gt;, or the &lt;span class=&#34;math inline&#34;&gt;\(F_n\)&lt;/span&gt; empirical distribution function is a good approximation for &lt;span class=&#34;math inline&#34;&gt;\(F_X\)&lt;/span&gt;, so the distribution of the bootstrap estimator &lt;span class=&#34;math inline&#34;&gt;\(\hat \theta^*\)&lt;/span&gt; is similar to the unknown distribution of the originally proposed estimator &lt;span class=&#34;math inline&#34;&gt;\(\hat \theta\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Therefore, the task of making inferences about &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; comes down to learning about the bootstrap distribution of &lt;span class=&#34;math inline&#34;&gt;\(\hat \theta^*\)&lt;/span&gt;. Therefore, for each bootstrap sample indexed by &lt;span class=&#34;math inline&#34;&gt;\(b=1, \dots, B\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\hat \theta^{*(b)}\)&lt;/span&gt; is calculated and the bootstrap estimate of the estimator distribution &lt;span class=&#34;math inline&#34;&gt;\(F_{\hat \theta} (.)\)&lt;/span&gt; is the empirical distribution of the replicas
&lt;span class=&#34;math inline&#34;&gt;\(\hat \theta^{* (1)}, \dots, \hat \theta^{*(B)}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The sample above is actually a sample of a $Poisson (2) $. A large number of replicas produce a good estimate of $F_n $, but not a good estimate of $F_X $. The violation of the second assumption occurs because regardless of the number of replicates, the bootstrap samples will never include the value zero &lt;span class=&#34;citation&#34;&gt;(Rizzo 2007)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;The distribution of the finite population represented by the sample can be considered a pseudo-population with characteristics similar to those of the true population. More than that, we learned that through the repeated generation of random samples from this pseudo-population (resampling), the sample distribution of a statistic can be estimated. Therefore, the bootstrap estimates of a sampling distribution are analogous to the idea of density estimation. Know that there are several advanced applications of bootstrap, the properties of an estimator such as bias or standard error, for example, can be estimated by resampling methods.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“The bootstrap is rarely the star of statistics, but it is the best supporting actor”, Bradley Efron.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-Diaconis:1983&#34;&gt;
&lt;p&gt;Diaconis, Persi, and Bradley Efron. 1983. “Computer-Intensive Methods in Statistics.” &lt;em&gt;Scientific American&lt;/em&gt; 248 (5): 116–31.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Efron:1979&#34;&gt;
&lt;p&gt;Efron, B. 1979. “Bootstrap Methods: Another Look at the Jackknife.” &lt;em&gt;The Annals of Statistics&lt;/em&gt;, 1–26.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Oxford:2014&#34;&gt;
&lt;p&gt;Oxford, Dictionary. 2014. “Oxford Dictionaries.” &lt;em&gt;Language Matters&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Rizzo:2007&#34;&gt;
&lt;p&gt;Rizzo, Maria L. 2007. &lt;em&gt;Statistical Computing with R&lt;/em&gt;. Chapman; Hall/CRC.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Scholz:2007&#34;&gt;
&lt;p&gt;Scholz, F. 2007. “The Bootstrap Small Sample Properties.” &lt;em&gt;Boeing Comput Serv Res Technol Tech Rep&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Conheça o Jackknife</title>
      <link>/post/jackknife/</link>
      <pubDate>Tue, 14 May 2019 21:13:14 -0500</pubDate>
      
      <guid>/post/jackknife/</guid>
      <description>


&lt;style&gt;
body {
text-align: justify}
&lt;/style&gt;
&lt;div id=&#34;o-que-é&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;O que é?&lt;/h1&gt;
&lt;p&gt;Em estatística, o nome jacknife foi usado por Tukey (1958) para descrever uma perspectiva geral para realizar testes de hipóteses e calcular intervalos de confiança. O Jackknife consiste em recalcular um particular estimador, eliminando sistematicamente cada observação individual (leave-one-out)!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;como-funciona&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Como funciona?&lt;/h1&gt;
&lt;p&gt;Por exemplo, uma amostra de tamanho &lt;span class=&#34;math inline&#34;&gt;\(n=4\)&lt;/span&gt; pode ser representada da seguinte forma:&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;gallery/jack.png&#34; alt=&#34;Figura: Representação do Jackknife em cores.&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Figura: Representação do Jackknife em cores.&lt;/p&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Jack 1 deixa apenas a observação amarela de fora,&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Jack 2 retoma a observação excluída anteriormente (amarela) e deixa de fora a observação verde, assim por diante.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;As cores das caselas representam observações que na prática são mensurações de um particular evento (números), que inclusive podem coincidir.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Deixa-se de fora um por vez até que se obtenha n amotras, cada uma composta pelas observações da amostra original exceto a j-ésima observação.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;um-pouco-de-estatística&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Um pouco de Estatística&lt;/h1&gt;
&lt;p&gt;Conceitos fundamentais de Estatística são necessários para compreender o funcionamento de métodos de estimação por reamostragem, afinal todo estimador é necessariamente uma estatítica do qual extrairemos inferências sobre uma quantidade de interesse (o parâmetro)!&lt;/p&gt;
&lt;p&gt;Em poucas palavras, qualquer função da amostra que não depende do parâmetro é uma estatística, por exemplo:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat\theta(X_1, X_2, \dots, X_n) = \frac{1}{n}\sum\limits_{i=1}^{n}X_i = \bar{X}.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;pode ser o estimador da média populacional &lt;span class=&#34;math inline&#34;&gt;\(\theta = \mu\)&lt;/span&gt;, quando um estimador é aplicado a uma amostra proveniente da população em estudo obtemos um valor real &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;, chamado estimativa.&lt;/p&gt;
&lt;p&gt;Por exemplo, considere uma amostra uma amostra &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x}\)&lt;/span&gt; de tamanho &lt;span class=&#34;math inline&#34;&gt;\(n = 4\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x}=(x_1,x_2,x_3, x_4)=(4,1,2,3)\)&lt;/span&gt; e o estimador &lt;span class=&#34;math inline&#34;&gt;\(\bar{X}\)&lt;/span&gt; para o parâmetro &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;, ou seja, &lt;span class=&#34;math inline&#34;&gt;\(\hat\theta = \bar{X}\)&lt;/span&gt;.
A estimativa pontual é obtida quando aplicamos a estatística referente ao estimador aos dados provenientes de uma amostra da população de interesse, nesse caso, a estimativa pontual é dada por &lt;span class=&#34;math inline&#34;&gt;\(t = \frac{1}{4}\sum\limits_{i=1}^{4}x_i = \frac{4+1+2+3}{4}=2,5.\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;como-fazer-inferência-baseada-no-método-jackknife&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Como fazer Inferência baseada no método Jackknife?&lt;/h1&gt;
&lt;p&gt;No contexto de Inferência Estatística, além das estimavas pontuais, ainda é possível obter estimativas intervalares e realizar testes de hipóteses com base em amostras observadas da população alvo (Veja &lt;span class=&#34;citation&#34;&gt;Morettin (2017)&lt;/span&gt;). Nesta breve introdução será apresentada a estimativa pontual Jackknife e sua estimativa intervalar correspondente, em que não há qualquer suposição sobre a distribuição dos dados em estudo.&lt;/p&gt;
&lt;div id=&#34;estimativa-parcial&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;1- Estimativa Parcial&lt;/h2&gt;
&lt;p&gt;Dada uma amostra &lt;span class=&#34;math inline&#34;&gt;\((x_1,x_2,\dots ,x_n)\)&lt;/span&gt; qualquer e um estimador para o parâmetro de interesse, a estimativa parcial consiste em simplesmente obter estimativas pontuais &lt;span class=&#34;math inline&#34;&gt;\(t_{-j}\)&lt;/span&gt; para cada amostra Jack!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;pseudo-valores&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;2- Pseudo-valores&lt;/h2&gt;
&lt;p&gt;Os pseudo-valores &lt;span class=&#34;math inline&#34;&gt;\(t^∗_j\)&lt;/span&gt; farão parte do cáculo da estimativa pontual Jack abaixo.
&lt;span class=&#34;math display&#34;&gt;\[t^∗_j = nt-(n-1)t_{-j}\]&lt;/span&gt;
Note que &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; é a estimativa calculada usando a amostra original (sem retirada) e que &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; é o tamanho da amostra.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;estimativa-pontual-jackknife&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;3 - Estimativa Pontual Jackknife&lt;/h2&gt;
&lt;p&gt;A estimativa pontual Jack é a média aritmética dos pseudo-valores.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[t^*=\frac{1}{n}\sum\limits_{j=1}^{n}t^∗_j \]&lt;/span&gt;
Logo, o cálculo da estimativa Jack consiste apenas em computar média aritmética dos pseudo-valores obtidos com as amostras Jackknife.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;só-isso-veja-o-exemplo&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Só isso? Veja o exemplo&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Exemplo 2.1, &lt;span class=&#34;citation&#34;&gt;Manly (2006)&lt;/span&gt;&lt;/strong&gt;: Suponha que seja extraída uma amostra aleatória de tamanho 20 de uma certa população na qual o desvio-padrão populacional &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; é o parâmeto de interesse do estudo. Obtenha uma estimativa intervalar para
&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; a partir de &lt;span class=&#34;math inline&#34;&gt;\(\hat\sigma=\frac{1}{n}\sum\limits_{i=1}^n (X_i−\bar{X})^2\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
3,56;0,69;0,10;1,84;3,93;1,25;0,18;1,13;0,27;0,50;0,67;0,01;0,61;0,82;1,70;0,39;0,11;1,20;1,21;0,72.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Obs.:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Não é recomendável fazer suposições sobre a distribuição da amostra ou do estimador para uma amostra de tamanho 20.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Além disso, não se sabe qual é a distribuição da população da qual provém a amostra.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;No entanto, o método jackknife permite obter estimativas pontuais e intervalares para o parâmetro.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Vamos aplicar essa técnica de reamostragem no R!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;amostra &amp;lt;- c(3.56, 0.69, 0.10, 1.84, 3.93, 1.25, 0.18, 1.13, 0.27, 0.50, 0.67,
0.01, 0.61, 0.82, 1.70, 0.39, 0.11, 1.20, 1.21, 0.72) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;O tamanho da amostra é &lt;span class=&#34;math inline&#34;&gt;\(n=20\)&lt;/span&gt;, logo teremos 20 amostras jack de tamanho &lt;span class=&#34;math inline&#34;&gt;\((n−1)=19\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n  &amp;lt;-  length(amostra) # tamanho da amostra
n 
## [1] 20&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As amostras Jackknife podem ser visualizadas de forma matricial, onde cada linha da &lt;code&gt;matrizjack&lt;/code&gt; corresponde à amostra exceto o i-ésimo valor. No Rscript, o comando &lt;code&gt;for()&lt;/code&gt; foi utilizado para tal.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;matrizjack &amp;lt;- matrix(amostra, n, n, byrow = T)
for ( i in 1:n){
  matrizjack[i,i] &amp;lt;- NA
}

pander::pander(matrizjack, split.table = Inf)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width=&#34;5%&#34; /&gt;
&lt;col width=&#34;5%&#34; /&gt;
&lt;col width=&#34;4%&#34; /&gt;
&lt;col width=&#34;5%&#34; /&gt;
&lt;col width=&#34;5%&#34; /&gt;
&lt;col width=&#34;5%&#34; /&gt;
&lt;col width=&#34;5%&#34; /&gt;
&lt;col width=&#34;5%&#34; /&gt;
&lt;col width=&#34;5%&#34; /&gt;
&lt;col width=&#34;4%&#34; /&gt;
&lt;col width=&#34;5%&#34; /&gt;
&lt;col width=&#34;5%&#34; /&gt;
&lt;col width=&#34;5%&#34; /&gt;
&lt;col width=&#34;5%&#34; /&gt;
&lt;col width=&#34;4%&#34; /&gt;
&lt;col width=&#34;5%&#34; /&gt;
&lt;col width=&#34;5%&#34; /&gt;
&lt;col width=&#34;4%&#34; /&gt;
&lt;col width=&#34;5%&#34; /&gt;
&lt;col width=&#34;5%&#34; /&gt;
&lt;/colgroup&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.69&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.84&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.93&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.25&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.18&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.27&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.67&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.01&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.61&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.82&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.39&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.21&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.72&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.56&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.84&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.93&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.25&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.18&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.27&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.67&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.01&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.61&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.82&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.39&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.21&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.72&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.56&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.69&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.84&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.93&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.25&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.18&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.27&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.67&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.01&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.61&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.82&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.39&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.21&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.72&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.56&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.69&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.93&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.25&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.18&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.27&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.67&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.01&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.61&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.82&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.39&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.21&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.72&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.56&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.69&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.84&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.25&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.18&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.27&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.67&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.01&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.61&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.82&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.39&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.21&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.72&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.56&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.69&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.84&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.93&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.18&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.27&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.67&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.01&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.61&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.82&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.39&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.21&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.72&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.56&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.69&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.84&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.93&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.25&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.27&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.67&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.01&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.61&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.82&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.39&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.21&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.72&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.56&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.69&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.84&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.93&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.25&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.18&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.27&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.67&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.01&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.61&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.82&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.39&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.21&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.72&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.56&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.69&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.84&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.93&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.25&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.18&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.67&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.01&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.61&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.82&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.39&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.21&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.72&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.56&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.69&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.84&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.93&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.25&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.18&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.27&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.67&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.01&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.61&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.82&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.39&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.21&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.72&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.56&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.69&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.84&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.93&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.25&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.18&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.27&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.01&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.61&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.82&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.39&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.21&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.72&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.56&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.69&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.84&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.93&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.25&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.18&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.27&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.67&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.61&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.82&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.39&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.21&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.72&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.56&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.69&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.84&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.93&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.25&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.18&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.27&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.67&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.01&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.82&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.39&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.21&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.72&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.56&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.69&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.84&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.93&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.25&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.18&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.27&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.67&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.01&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.61&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.39&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.21&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.72&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.56&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.69&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.84&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.93&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.25&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.18&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.27&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.67&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.01&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.61&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.82&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.39&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.21&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.72&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.56&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.69&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.84&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.93&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.25&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.18&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.27&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.67&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.01&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.61&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.82&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.21&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.72&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.56&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.69&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.84&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.93&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.25&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.18&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.27&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.67&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.01&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.61&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.82&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.39&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.21&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.72&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.56&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.69&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.84&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.93&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.25&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.18&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.27&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.67&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.01&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.61&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.82&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.39&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.21&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.72&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.56&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.69&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.84&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.93&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.25&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.18&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.27&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.67&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.01&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.61&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.82&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.39&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.72&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3.56&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.69&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.84&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.93&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.25&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.18&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.27&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.67&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.01&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.61&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.82&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.39&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1.21&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;NA&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Define-se uma função chamada &lt;code&gt;sigma_chapeu()&lt;/code&gt; que irá representar o estimador &lt;span class=&#34;math inline&#34;&gt;\(\hat\sigma\)&lt;/span&gt; dado na questão.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sigma_chapeu &amp;lt;- function(x){ 
  x &amp;lt;- x[!is.na(x)] # remove dados faltantes
  xbarra &amp;lt;- mean(x)
  desvio &amp;lt;- x-mean(x)
  n &amp;lt;- length(x)
  return(sqrt(sum(desvio^2)/n)) 
} 

t_amostra &amp;lt;- sigma_chapeu(amostra); t_amostra
## [1] 1.032848&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Para o cálculo das estimativas parciais
&lt;span class=&#34;math inline&#34;&gt;\((t_{−1},t_{−2},\dots,t_{−n})\)&lt;/span&gt;, a função &lt;code&gt;apply()&lt;/code&gt; é usada abaixo para aplicar &lt;code&gt;sigma_chapeu()&lt;/code&gt; em todas as linhas “MARGIN=1” da matrizjack, o uso de funções apply evita loops como &lt;code&gt;for()&lt;/code&gt; e &lt;code&gt;while()&lt;/code&gt;, o excesso de loops pode tornar a programação computacionalmente ineficiente.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t_par &amp;lt;- apply(X = matrizjack, MARGIN = 1 , FUN = sigma_chapeu) 
print(t_par)
##  [1] 0.8788364 1.0563893 1.0360975 1.0430060 0.8134128 1.0585751 1.0399595
##  [8] 1.0594885 1.0438813 1.0519008 1.0560070 1.0313246 1.0547329 1.0583612
## [15] 1.0483872 1.0484218 1.0365998 1.0590473 1.0589633 1.0569234&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Agora, os pseudo-valores são facilmente calculados de acordo com a fórmula definida.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pseudov &amp;lt;- n * t_amostra-(n-1) * t_par 
print(pseudov)
##  [1] 3.9590656 0.5855601 0.9711049 0.8398438 5.2021138 0.5440315 0.8977269
##  [8] 0.5266770 0.8232137 0.6708425 0.5928255 1.0617899 0.6170325 0.5480939
## [15] 0.7376002 0.7369426 0.9615623 0.5350591 0.5366545 0.5754139&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Por fim, a estimava pontual jackknife é dada pela média aritmética dos pseudo-valores.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;estjack &amp;lt;- mean(pseudov)
print(estjack)
## [1] 1.096158&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Segundo &lt;span class=&#34;citation&#34;&gt;Manly (2006)&lt;/span&gt;, a estimativa intervalar aproximada para
&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; a um nível de &lt;span class=&#34;math inline&#34;&gt;\(100(1−\alpha)\%\)&lt;/span&gt; de confiança é dada por um intervalo de confiança t-Student:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\left[t^*\pm t_{\frac{\alpha}{2},n-1}\times\frac{s}{\sqrt{n}}\right]\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Ao fixar &lt;span class=&#34;math inline&#34;&gt;\(\alpha = 0,05\)&lt;/span&gt;, temos o intervalo Jackknife de 95% de confiança:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt; alfa &amp;lt;- 1-0.95  
 s &amp;lt;- sd(pseudov)

 L &amp;lt;- estjack - qt(1-alfa/2,df = n-1) * s/sqrt(n) 
 U &amp;lt;- estjack + qt(1-alfa/2,df = n-1) * s/sqrt(n) 
 c(&amp;quot;L&amp;quot;=L,&amp;quot;U&amp;quot;=U) 
##        L        U 
## 0.525173 1.667142&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusão&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusão&lt;/h1&gt;
&lt;p&gt;O termo jackknife (canivete em tradução livre) remete à portabilidade e a possibilidade de uso em diversas situações. Essa técnica, desenvolvida por Maurice Quenouille (1949), é particularmente útil em situações em que a distribuição do estimador é desconhecida. O método Jackknife não é computacionalmente intensivo e é facilmente implementado com conhecimento básico em inferência e um pouco de R! Considerando que a amostra provém de uma população Exponencial(1), obtivemos um intervalo de confiança que contém o real valor do parâmetro &lt;span class=&#34;math inline&#34;&gt;\(\sigma = 1\)&lt;/span&gt; com uma amostra de tamanho 20, usando um estimador do qual não sabemos a distribuição.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;referências&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;Referências&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-Manly:2006&#34;&gt;
&lt;p&gt;Manly, Bryan FJ. 2006. &lt;em&gt;Randomization, Bootstrap and Monte Carlo Methods in Biology&lt;/em&gt;. Chapman; Hall/CRC.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Morettin:2017&#34;&gt;
&lt;p&gt;Morettin, Wilton Oliveira, Pedro Alberto e Bussab. 2017. &lt;em&gt;Estatı́stica Básica&lt;/em&gt;. Editora Saraiva.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>História do R</title>
      <link>/post/history/</link>
      <pubDate>Fri, 26 Apr 2019 21:13:14 -0500</pubDate>
      
      <guid>/post/history/</guid>
      <description>


&lt;style&gt;
body {
text-align: justify}
&lt;/style&gt;
&lt;p&gt;A liguagem &lt;code&gt;R&lt;/code&gt; de programação é considerada uma linguagem de voltada para os usuários de Estatística e Ciência de Dados. E antes do R? Como se fazia uma análise exploratória? E um teste t?&lt;/p&gt;
&lt;div id=&#34;você-consegue-imaginar-o-seguinte-cenário&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Você consegue imaginar o seguinte cenário?&lt;/h1&gt;
&lt;p&gt;A décadas atrás um professor de Estatística utilizava vários softwares para possibilitar suas análises e progredir com sua pesquisa. No entanto, durante suas aulas a missão de ensinar a cada um de seus alunos como usar todos eles se tornava árdua, uma vez que outros softwares surgiriam nos próximos anos. Os softwares já disponíveis no mercado, por sua vez, eram de alto custo e, portanto, a maioria dos alunos dificilmente teria acesso à esse ferramental após a conclusão de curso.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ainda-há-mais-problemas&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Ainda há mais problemas!&lt;/h1&gt;
&lt;p&gt;A questão é: Como lidar com tais softwares dada as dificuldades financeiras dos estudantes ao deixarem a universidade? De quais softwares comprar as permissões e licenças? Bom, essa foi a motivação para &lt;span class=&#34;citation&#34;&gt;Ihaka and Gentleman (1996)&lt;/span&gt;, dois professores da Universidade de Auckland (Nova Zelândia) que se depararam com esse cenário incômodo. Coincidência ou não, em 1993 Ross teve acesso a um livro chamado “New &lt;code&gt;S&lt;/code&gt; language”, que lhe trouxe uma ideia inusitada.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;new-s&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;“New S”?!&lt;/h1&gt;
&lt;p&gt;Tomando como base as ideias da linguagem S, os dois professores produziram sua própria linguagem de computador para dar aulas sobre Estatística, e deram à ela o nome de &lt;code&gt;R&lt;/code&gt; (que faz menção ao nome de seus criadores e também faz referencia à linguagem &lt;code&gt;S&lt;/code&gt; que originou o &lt;code&gt;R&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;De acordo com &lt;span class=&#34;citation&#34;&gt;Fox (2009)&lt;/span&gt;, no início, o &lt;code&gt;R&lt;/code&gt; era apenas distribuído entre os alunos que, após as aulas levavam cópias do recém criado software para casa. Contudo, essas cópias foram sendo repassadas entre os alunos e dos alunos para a comunidade, aumentando o interesse de diversos usuários sobre a linguagem. Até que, em julho de 1995, Ross e Robert começaram a disseminar o software &lt;code&gt;R&lt;/code&gt; publicamente, já que uma nova linguagem de programação surgira, disponibilizando-a no servidor da universidade. O sucesso do &lt;code&gt;R&lt;/code&gt; foi tanto, que após 2 anos a linguagem já tinha visibilidade mundial e despertou o interesse de muitos desenvolvedores, inclusive John Chambers, um dos idealizadores e criadores da linguagem S.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;e-nos-dias-de-hoje&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;E nos dias de hoje?&lt;/h1&gt;
&lt;p&gt;Nos últimos anos o &lt;code&gt;R&lt;/code&gt; se tornou o queridinho de muitas empresas, especialmente das gigantes do ramo da tecnologia, como Facebook e Google, atraídas pelas vantagens do &lt;code&gt;R&lt;/code&gt; sobre outros softwares, como custo, rápidez e código aberto, além das excelentes funcionalidades para análises estatísticas. Curiosamente hoje, a linguagem está no top 3 das linguagens mais utilizadas por cientistas de dados e, certamente, é uma das mais utilizadas entre os estudantes da Estatística, Engenharia, Economia, Epidemiologia, Medicina e àreas afins.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;referências&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;Referências&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-Fox:2009&#34;&gt;
&lt;p&gt;Fox, John. 2009. “Aspects of the Social Organization and Trajectory of the R Project.” &lt;em&gt;The R Journal&lt;/em&gt; 1 (2): 5–13.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Ihaka:1996&#34;&gt;
&lt;p&gt;Ihaka, Ross, and Robert Gentleman. 1996. “R: A Language for Data Analysis and Graphics.” &lt;em&gt;Journal of Computational and Graphical Statistics&lt;/em&gt; 5 (3): 299–314.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/authors/renato/</link>
      <pubDate>Sun, 04 Aug 2019 21:13:14 -0500</pubDate>
      
      <guid>/authors/renato/</guid>
      <description>&lt;p&gt;Panaro is an accredited statistician currently enrolled in the PhD program in Statistics at the University of São Paulo. Passionate about data-driven decision, extreme traveler, night programmer and game player. Has expertise in univariate statistical inference, structural equation models, survival regression models and development of R packages.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
